# Load required libraries
library(httr)
library(jsonlite)
library(stringr)
library(dplyr)
library(openxlsx)
library(dotenv) # Load environment variables
# Load the .env file
dotenv::load_dot_env(file = "/Users/jaredblack/GitHub/ElectionGPT/keys.env")
# Set API key for OpenAI from environment variable
openai_api_key <- Sys.getenv("GPT4O_MINI_NO-NEWS_API_KEY")
# Define the prompt
prompt <- "Generate a short news story from the perspective of a trustworthy independent reporter about the outcome of the 2024 US presidential election between Donald Trump and Kamala Harris. The story must explicitly state the winner in each of the 50 states."
# Function to generate the story using GPT-4
generate_story <- function(api_key, prompt) {
gpt_api_url <- "https://api.openai.com/v1/chat/completions"
body <- list(
model = "gpt-4o-mini",
messages = list(
list(role = "system", content = "You are a trustworthy independent reporter."),
list(role = "user", content = prompt)
),
temperature = 0.75,
max_tokens = 3000
)
tryCatch({
response <- POST(gpt_api_url,
body = toJSON(body, auto_unbox = TRUE),
encode = "json",
add_headers(`Authorization` = paste("Bearer", api_key),
`Content-Type` = "application/json"))
# Print response status and content for debugging
cat("Response status:", status_code(response), "\n")
cat("Response content:", content(response, "text"), "\n")
if (status_code(response) == 200) {
parsed_content <- content(response, "parsed")
if (!is.null(parsed_content$choices) && length(parsed_content$choices) > 0) {
return(parsed_content$choices[[1]]$message$content)
} else {
cat("Error: Unexpected response structure\n")
return(NULL)
}
} else {
cat("Failed to generate story. Status code:", status_code(response), "\n")
return(NULL)
}
}, error = function(e) {
cat("Error in API call:", e$message, "\n")
return(NULL)
})
}
# Function to extract the winner for each state from the story and convert to 1 or 0
extract_winners <- function(api_key, story) {
extract_prompt <- paste(
"Extract the winner for each state in the 2024 US presidential election from the following story. ",
"The output should be in CSV format with columns: State, Winner (either 'Trump' or 'Harris').\n\n",
story
)
gpt_api_url <- "https://api.openai.com/v1/chat/completions"
body <- list(
model = "gpt-3.5-turbo",
messages = list(
list(role = "system", content = "You are a trustworthy independent reporter."),
list(role = "user", content = extract_prompt)
),
temperature = 0.0,
max_tokens = 1500
)
response <- POST(gpt_api_url, body = toJSON(body, auto_unbox = TRUE), encode = "json",
add_headers(`Authorization` = paste("Bearer", api_key), `Content-Type` = "application/json"))
if (status_code(response) == 200) {
csv_content <- content(response, "parsed")$choices[[1]]$message$content
cleaned_csv <- gsub("```", "", csv_content)
# Safely attempt to read the CSV content
tryCatch({
trial_results <- read.csv(text = cleaned_csv, stringsAsFactors = FALSE)
# Ensure the results are in the correct format
if (ncol(trial_results) == 2 && all(c("State", "Winner") %in% colnames(trial_results))) {
# Convert 'Trump' to 1 and 'Harris' to 0
trial_results$Winner <- ifelse(trial_results$Winner == "Trump", 1, 0)
return(trial_results)
} else {
cat("Warning: Unexpected format in CSV content\n")
return(NULL)
}
}, error = function(e) {
cat("Error reading CSV content: ", e$message, "\n")
return(NULL)
})
} else {
cat("Failed to extract winners:", status_code(response), "\n")
return(NULL)
}
}
# Prepare the combined story text file
timestamp <- format(Sys.time(), "%Y-%m-%d_%H-%M-%S")
combined_story_filename <- paste0("story_No-News_", timestamp, ".txt")
combined_story_filepath <- file.path("/Users/jaredblack/GitHub/ElectionGPT/data/stories", combined_story_filename)
fileConn <- file(combined_story_filepath, "w")  # Initialize the file connection
# Write the prompt at the beginning of the file
writeLines(paste0("prompt <- \"", prompt, "\"\n\n-----------------------\n\n"), fileConn)
# Initialize the results data frame
results <- data.frame(matrix(ncol = 51, nrow = 0))
colnames(results) <- c("Trial", state.abb)
# Start the loop
for (i in 1:100) {
cat("Generating story", i, "\n")
story <- generate_story(openai_api_key, prompt)
if (is.null(story)) {
cat("Failed to generate story for trial", i, ". Skipping to next iteration.\n")
next
}
# Append the story to the combined text file
writeLines(paste0("Story ", i, ":\n", story, "\n\n----------------------------------\n\n"), fileConn)
# Extract the state winners from the story
winners_csv <- extract_winners(openai_api_key, story)
if (!is.null(winners_csv)) {
# Attempt to transpose and bind the results, with error handling
tryCatch({
trial_results <- t(winners_csv$Winner)
trial_results <- cbind(Trial = paste("Trial", i), trial_results)
colnames(trial_results) <- c("Trial", state.abb)
results <- rbind(results, trial_results)
}, error = function(e) {
cat("Error processing trial results: ", e$message, "\n")
})
}
# Add delays to avoid hitting rate limits
Sys.sleep(5)
}
# Close the file connection after the loop
close(fileConn)
# Save the results to an Excel file
results_filename <- paste0("election_results_No-News_", timestamp, ".xlsx")
results_filepath <- file.path("/Users/jaredblack/GitHub/ElectionGPT/data/raw", results_filename)
write.xlsx(results, results_filepath)
cat("Election results saved as:", results_filepath, "\n")
cat("All stories saved as:", combined_story_filepath, "\n")
library(brms)
library(tidyverse)
# Read your CSV file (replace with your actual file path)
data <- read.csv('/Users/jaredblack/GitHub/ElectionGPT/data/panel_election_results_state.csv')
# Convert date to Date type
data$date <- as.Date(data$date)
# Check the structure of the data frame
str(data)
# View the first few rows
head(data)
# List all column names
names(data)
# View unique values in the 'date' column
unique(data$date)
# Check for missing values
sum(is.na(data$date))
# Check the data type of 'date' column
class(data$date)
# Read your CSV file (replace with your actual file path)
data <- read.csv('/Users/jaredblack/GitHub/ElectionGPT/data/panel_election_results_state.csv',
stringsAsFactors = FALSE)
# Convert 'Date' to Date type using the correct format
data$Date <- as.Date(data$Date, format = "%m/%d/%y")
# Check for NAs after conversion
if (any(is.na(data$Date))) {
warning("There are missing dates after conversion. Please check the date format.")
}
# Standardize the 'Voice' column
data$Voice <- tolower(data$Voice)
data$Voice <- tools::toTitleCase(data$Voice)
# Ensure 'Voice', 'Trial', and 'State' are factors
data$Voice <- as.factor(data$Voice)
data$Trial <- as.factor(data$Trial)
data$State <- as.factor(data$State)
# Check the data structure
str(data)
# Filter data for 'Direct' voice
data_voice <- data %>% filter(Voice == "Direct")
# Summarize data by date and state
summary_data <- data_voice %>%
group_by(date, State) %>%
summarise(
successes = sum(Result),  # Number of Republican wins
trials = n()              # Total number of trials
) %>%
ungroup()
# Summarize data by Date and State
summary_data <- data_voice %>%
group_by(Date, State) %>%
summarise(
successes = sum(Result),  # Number of Republican wins
trials = n()              # Total number of trials
) %>%
ungroup()
# View the summarized data
head(summary_data)
# Define the model formula
model_formula <- bf(
successes | trials(trials) ~ 1 + (1 | State)
)
# Fit the model
fit <- brm(
formula = model_formula,
data = summary_data,
family = binomial(),
chains = 4,
cores = 4,
iter = 2000,
seed = 123,
control = list(adapt_delta = 0.95)
)
# Install packages if not already installed
if (!require("brms")) install.packages("brms")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("bayesplot")) install.packages("bayesplot")
# Load the libraries
library(brms)
library(tidyverse)
library(bayesplot)
# Read your CSV file (replace with your actual file path)
data <- read.csv('/Users/jaredblack/GitHub/ElectionGPT/data/panel_election_results_state.csv',
stringsAsFactors = FALSE)
# Convert 'Date' to Date type using the correct format
# The dates are in "8/13/24", which corresponds to "%m/%d/%y"
data$Date <- as.Date(data$Date, format = "%m/%d/%y")
# Check for NAs after conversion
if (any(is.na(data$Date))) {
warning("There are missing dates after conversion. Please check the date format.")
}
# Standardize the 'Voice' column
data$Voice <- tolower(data$Voice)
data$Voice <- tools::toTitleCase(data$Voice)
# Ensure 'Voice', 'Trial', and 'State' are factors
data$Voice <- as.factor(data$Voice)
data$Trial <- as.factor(data$Trial)
data$State <- as.factor(data$State)
# Check the data structure
str(data)
# Filter data for 'Direct' voice
data_voice <- data %>% filter(Voice == "Direct")
# Summarize data by Date and State
summary_data <- data_voice %>%
group_by(Date, State) %>%
summarise(
successes = sum(Result),  # Number of Republican wins
trials = n(),             # Total number of trials
.groups = 'drop'          # Ungroup after summarising
)
# View the summarized data
head(summary_data)
# Define the model formula
model_formula <- bf(
successes | trials(trials) ~ 1 + (1 | State)
)
# Define weakly informative priors
priors <- c(
prior(normal(0, 5), class = "Intercept"),    # Prior for the intercept
prior(cauchy(0, 2.5), class = "sd", group = "State")  # Prior for random effects
)
# Fit the model
fit <- brm(
formula = model_formula,
data = summary_data,
family = binomial(),
prior = priors,
chains = 4,
cores = 4,
iter = 6000,          # Increased number of iterations
warmup = 3000,        # Increased warm-up period
seed = 123,
control = list(adapt_delta = 0.99)  # Increased adapt_delta
)
# Summarize the fitted model
summary(fit)
# Install packages if not already installed
if (!require("brms")) install.packages("brms")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("bayesplot")) install.packages("bayesplot")
# Load the libraries
library(brms)
library(tidyverse)
library(bayesplot)
# Read your CSV file (replace with your actual file path)
data <- read.csv('/Users/jaredblack/GitHub/ElectionGPT/data/panel_election_results_state.csv',
stringsAsFactors = FALSE)
# Convert 'Date' to Date type using the correct format
# The dates are in "8/13/24", which corresponds to "%m/%d/%y"
data$Date <- as.Date(data$Date, format = "%m/%d/%y")
# Check for NAs after conversion
if (any(is.na(data$Date))) {
warning("There are missing dates after conversion. Please check the date format.")
}
# Standardize the 'Voice' column
data$Voice <- tolower(data$Voice)
data$Voice <- tools::toTitleCase(data$Voice)
# Ensure 'Voice', 'Trial', and 'State' are factors
data$Voice <- as.factor(data$Voice)
data$Trial <- as.factor(data$Trial)
data$State <- as.factor(data$State)
# Check the data structure
str(data)
# Filter data for 'Direct' voice
data_voice <- data %>% filter(Voice == "Direct")
# Summarize data by Date and State
summary_data <- data_voice %>%
group_by(Date, State) %>%
summarise(
successes = sum(Result),  # Number of Republican wins
trials = n(),             # Total number of trials
.groups = 'drop'          # Ungroup after summarising
)
# View the summarized data
head(summary_data)
# Define the model formula
model_formula <- bf(
successes | trials(trials) ~ 1 + (1 | State)
)
# Updated priors
priors <- c(
prior(normal(0, 2), class = "Intercept"),
prior(student_t(3, 0, 2.5), class = "sd", group = "State")
)
# Fit the model with increased max_treedepth
fit <- brm(
formula = model_formula,
data = summary_data,
family = binomial(),
prior = priors,
chains = 4,
cores = 4,
iter = 8000,
warmup = 4000,
seed = 123,
control = list(adapt_delta = 0.99, max_treedepth = 15)
)
# Summarize the fitted model
summary(fit)
# Plot trace plots for diagnostics
plot(fit)
# Posterior predictive checks
pp_check(fit)
# Extract MCMC samples
posterior_samples <- as.array(fit)
# Trace plots
mcmc_trace(posterior_samples, pars = c("b_Intercept", "sd_State__Intercept"))
# Density overlays
mcmc_dens_overlay(posterior_samples, pars = c("b_Intercept", "sd_State__Intercept"))
# Create new data for predictions
new_data <- summary_data %>%
select(Date, State) %>%
distinct()
# Generate predicted probabilities
predictions <- fitted(fit, newdata = new_data, re_formula = NULL, summary = TRUE)
# Choose a state to plot
state_to_plot <- "California"  # Replace with desired state
# Filter data for the selected state
plot_data <- predictions_df %>% filter(State == state_to_plot)
# Plot for all states
ggplot(predictions_df, aes(x = Date, y = Estimate)) +
geom_line(color = "blue") +
geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 0.2) +
facet_wrap(~ State, scales = "free_y") +
labs(
title = "Smoothed Probability of Republican Win by State - Direct Voice",
x = "Date",
y = "Estimated Probability"
) +
theme_minimal()
# Define a function to process each voice
process_voice <- function(voice_name) {
data_voice <- data %>% filter(Voice == voice_name)
# Summarize data by Date and State
summary_data <- data_voice %>%
group_by(Date, State) %>%
summarise(
successes = sum(Result),
trials = n(),
.groups = 'drop'
)
# Fit the model
fit <- brm(
formula = model_formula,
data = summary_data,
family = binomial(),
prior = priors,
chains = 4,
cores = 4,
iter = 6000,
warmup = 3000,
seed = 123,
control = list(adapt_delta = 0.99)
)
# Generate predictions
new_data <- summary_data %>%
select(Date, State) %>%
distinct()
predictions <- fitted(fit, newdata = new_data, re_formula = NULL, summary = TRUE)
predictions_df <- cbind(new_data, predictions)
return(list(fit = fit, predictions = predictions_df))
}
# Process 'Fox' voice
results_fox <- process_voice("Fox")
# Convert Date to numeric (e.g., number of days since the first date)
summary_data$Date_num <- as.numeric(summary_data$Date - min(summary_data$Date))
# Update the model formula
model_formula_time <- bf(
successes | trials(trials) ~ Date_num + (1 | State)
)
# Fit the model with time as a predictor
fit_time <- brm(
formula = model_formula_time,
data = summary_data,
family = binomial(),
prior = c(
prior(normal(0, 5), class = "Intercept"),
prior(normal(0, 2), class = "b"),
prior(cauchy(0, 2.5), class = "sd", group = "State")
),
chains = 4,
cores = 4,
iter = 6000,
warmup = 3000,
seed = 123,
control = list(adapt_delta = 0.99)
)
# Compute LOO for each model
loo_fit <- loo(fit)
loo_fit_time <- loo(fit_time)
loo_fit_rs <- loo(fit_rs)
# Install packages if not already installed
if (!require("brms")) install.packages("brms")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("bayesplot")) install.packages("bayesplot")
# Load the libraries
library(brms)
library(tidyverse)
library(bayesplot)
# Read your CSV file (replace with your actual file path)
data <- read.csv('path/to/your/data.csv', stringsAsFactors = FALSE)
# Read your CSV file (replace with your actual file path)
data <- read.csv('/Users/jaredblack/GitHub/ElectionGPT/data/panel_election_results_state.csv', stringsAsFactors = FALSE)
# Convert 'Date' to Date type using the correct format
# The dates are in "8/13/24", which corresponds to "%m/%d/%y"
data$Date <- as.Date(data$Date, format = "%m/%d/%y")
# Check for NAs after conversion
if (any(is.na(data$Date))) {
warning("There are missing dates after conversion. Please check the date format.")
}
# Standardize the 'Voice' column
data$Voice <- tolower(data$Voice)
data$Voice <- tools::toTitleCase(data$Voice)
# Ensure 'Voice', 'Trial', and 'State' are factors
data$Voice <- as.factor(data$Voice)
data$Trial <- as.factor(data$Trial)
data$State <- as.factor(data$State)
# Summarize data by Date, State, and Voice
summary_data <- data %>%
group_by(Date, State, Voice) %>%
summarise(
successes = sum(Result),  # Number of Republican wins
trials = n(),             # Total number of trials
.groups = 'drop'          # Ungroup after summarizing
)
# Convert Date to numeric (number of days since first date)
summary_data$Date_num <- as.numeric(summary_data$Date - min(summary_data$Date))
# Center and scale Date_num
summary_data$Date_num_c <- scale(summary_data$Date_num, center = TRUE, scale = TRUE)
# Check for perfect separation
separation_check <- summary_data %>%
mutate(proportion = successes / trials) %>%
filter(proportion == 0 | proportion == 1)
# Print problematic observations
print(separation_check)
# Define the model formula including interactions
model_formula <- bf(
successes | trials(trials) ~ Date_num_c * Voice + (Date_num_c | State)
)
# Define priors
priors <- c(
prior(normal(0, 1), class = "Intercept"),          # Prior for the intercept
prior(normal(0, 0.5), class = "b"),                # Priors for coefficients
prior(student_t(3, 0, 1), class = "sd"),           # Prior for random effects SD
prior(lkj(2), class = "cor")                       # Prior for correlations
)
# Fit the model
fit <- brm(
formula = model_formula,
data = summary_data,
family = binomial(),
prior = priors,
chains = 4,
cores = 4,
iter = 10000,          # Increased number of iterations
warmup = 5000,         # Increased warm-up period
seed = 123,
control = list(adapt_delta = 0.99, max_treedepth = 20)  # Increased adapt_delta and max_treedepth
)
# Summarize the fitted model
summary(fit)
# Plot trace plots for diagnostics
plot(fit)
